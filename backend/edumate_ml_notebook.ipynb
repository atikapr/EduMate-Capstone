{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed96584",
   "metadata": {},
   "source": [
    "# EduMate - Sistem Rekomendasi Pembelajaran\n",
    "# Notebook untuk Eksplorasi Data dan Pengembangan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1817af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d527a",
   "metadata": {},
   "source": [
    "## 1. LOADING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1afb653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "‚úÖ Data mahasiswa: (300, 10)\n",
      "‚úÖ Data konten: (200, 8)\n",
      "‚úÖ Data interaksi: (3000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "data_mahasiswa = pd.read_csv('data_mahasiswa.csv')\n",
    "data_konten = pd.read_csv('data_konten.csv') \n",
    "data_interaksi = pd.read_csv('interaksi_user_konten.csv')\n",
    "\n",
    "print(f\"‚úÖ Data mahasiswa: {data_mahasiswa.shape}\")\n",
    "print(f\"‚úÖ Data konten: {data_konten.shape}\")\n",
    "print(f\"‚úÖ Data interaksi: {data_interaksi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19ee46",
   "metadata": {},
   "source": [
    "## 2. EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b6d5ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Data Overview:\n",
      "\n",
      "--- Data Mahasiswa ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id_mahasiswa            300 non-null    object \n",
      " 1   nama                    300 non-null    object \n",
      " 2   jurusan                 300 non-null    object \n",
      " 3   angkatan                300 non-null    int64  \n",
      " 4   ipk_terakhir            300 non-null    float64\n",
      " 5   device_preference       300 non-null    object \n",
      " 6   learning_style          300 non-null    object \n",
      " 7   goal                    300 non-null    object \n",
      " 8   waktu_belajar_per_hari  300 non-null    int64  \n",
      " 9   ketersediaan_belajar    300 non-null    object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 23.6+ KB\n",
      "None\n",
      "         angkatan  ipk_terakhir  waktu_belajar_per_hari\n",
      "count   300.00000    300.000000               300.00000\n",
      "mean   2021.06000      2.997700                 3.03000\n",
      "std       1.38424      0.394022                 1.43619\n",
      "min    2019.00000      1.700000                 1.00000\n",
      "25%    2020.00000      2.727500                 2.00000\n",
      "50%    2021.00000      3.020000                 3.00000\n",
      "75%    2022.00000      3.250000                 4.00000\n",
      "max    2023.00000      4.540000                 5.00000\n",
      "\n",
      "--- Data Konten ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id_konten        200 non-null    object \n",
      " 1   judul            200 non-null    object \n",
      " 2   mata_kuliah      200 non-null    object \n",
      " 3   platform         200 non-null    object \n",
      " 4   format           200 non-null    object \n",
      " 5   durasi           200 non-null    int64  \n",
      " 6   kesulitan        200 non-null    object \n",
      " 7   rating_pengguna  200 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 12.6+ KB\n",
      "None\n",
      "          durasi  rating_pengguna\n",
      "count  200.00000       200.000000\n",
      "mean    66.74000         3.856800\n",
      "std     30.86219         0.756164\n",
      "min     10.00000         2.530000\n",
      "25%     40.00000         3.292500\n",
      "50%     69.00000         3.885000\n",
      "75%     93.00000         4.530000\n",
      "max    120.00000         5.000000\n",
      "\n",
      "--- Data Interaksi ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id_interaksi   3000 non-null   object\n",
      " 1   id_mahasiswa   3000 non-null   object\n",
      " 2   id_konten      3000 non-null   object\n",
      " 3   waktu_akses    3000 non-null   object\n",
      " 4   durasi_tonton  3000 non-null   int64 \n",
      " 5   feedback       3000 non-null   object\n",
      " 6   device         3000 non-null   object\n",
      " 7   status         3000 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 187.6+ KB\n",
      "None\n",
      "       durasi_tonton\n",
      "count    3000.000000\n",
      "mean       62.633333\n",
      "std        33.348157\n",
      "min         5.000000\n",
      "25%        33.000000\n",
      "50%        63.000000\n",
      "75%        91.250000\n",
      "max       120.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Data Overview:\")\n",
    "print(\"\\n--- Data Mahasiswa ---\")\n",
    "print(data_mahasiswa.info())\n",
    "print(data_mahasiswa.describe())\n",
    "\n",
    "print(\"\\n--- Data Konten ---\")\n",
    "print(data_konten.info()) \n",
    "print(data_konten.describe())\n",
    "\n",
    "print(\"\\n--- Data Interaksi ---\")\n",
    "print(data_interaksi.info())\n",
    "print(data_interaksi.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7dbdc",
   "metadata": {},
   "source": [
    "## 3. DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d1a04d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Starting Data Preprocessing...\n",
      "üîó Merging datasets...\n",
      "‚úÖ Merged data shape: (3000, 28)\n",
      "üõ†Ô∏è Handling missing values...\n",
      "üè∑Ô∏è Encoding categorical features...\n",
      "‚úÖ Label encoders created for 9 features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Starting Data Preprocessing...\")\n",
    "\n",
    "# 3.1 Konversi feedback ke numerik\n",
    "feedback_mapping = {\n",
    "    'Sangat Membantu': 5,\n",
    "    'Bermanfaat': 4, \n",
    "    'Cukup': 3,\n",
    "    'Kurang': 2,\n",
    "    'Tidak Membantu': 1\n",
    "}\n",
    "\n",
    "data_interaksi['feedback_score'] = data_interaksi['feedback'].map(feedback_mapping)\n",
    "\n",
    "# 3.2 Konversi status ke numerik\n",
    "data_interaksi['completion_score'] = data_interaksi['status'].map({\n",
    "    'Selesai': 1,\n",
    "    'Belum Selesai': 0\n",
    "})\n",
    "\n",
    "# 3.3 Feature engineering untuk durasi normalized\n",
    "data_interaksi = data_interaksi.merge(data_konten[['id_konten', 'durasi']], on='id_konten', how='left')\n",
    "data_interaksi['watch_ratio'] = data_interaksi['durasi_tonton'] / data_interaksi['durasi']\n",
    "data_interaksi['watch_ratio'] = data_interaksi['watch_ratio'].clip(0, 1)  # Cap at 100%\n",
    "\n",
    "# 3.4 Gabung semua data\n",
    "print(\"üîó Merging datasets...\")\n",
    "full_data = data_interaksi.merge(data_mahasiswa, on='id_mahasiswa', how='left')\n",
    "full_data = full_data.merge(data_konten, on='id_konten', how='left')\n",
    "\n",
    "print(f\"‚úÖ Merged data shape: {full_data.shape}\")\n",
    "\n",
    "# 3.5 Handle missing values\n",
    "print(\"üõ†Ô∏è Handling missing values...\")\n",
    "numeric_cols = full_data.select_dtypes(include=[np.number]).columns\n",
    "full_data[numeric_cols] = full_data[numeric_cols].fillna(full_data[numeric_cols].median())\n",
    "\n",
    "categorical_cols = full_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    full_data[col] = full_data[col].fillna('Unknown')\n",
    "\n",
    "# 3.6 Label Encoding untuk fitur kategorikal\n",
    "print(\"üè∑Ô∏è Encoding categorical features...\")\n",
    "label_encoders = {}\n",
    "categorical_features = ['jurusan', 'device_preference', 'learning_style', 'goal', \n",
    "                       'ketersediaan_belajar', 'mata_kuliah', 'platform', 'format', 'kesulitan']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in full_data.columns:\n",
    "        le = LabelEncoder()\n",
    "        full_data[f'{feature}_encoded'] = le.fit_transform(full_data[feature].astype(str))\n",
    "        label_encoders[feature] = le\n",
    "\n",
    "print(f\"‚úÖ Label encoders created for {len(label_encoders)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908a089",
   "metadata": {},
   "source": [
    "## 4. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc3227eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è Feature Engineering...\n",
      "üìä Creating user-item matrix...\n",
      "‚úÖ User-item matrix shape: (300, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n‚öôÔ∏è Feature Engineering...\")\n",
    "\n",
    "# 4.1 User profile features (untuk content-based filtering)\n",
    "user_features = ['jurusan_encoded', 'learning_style_encoded', 'goal_encoded', \n",
    "                'ketersediaan_belajar_encoded', 'device_preference_encoded', 'ipk_terakhir', 'waktu_belajar_per_hari']\n",
    "\n",
    "# 4.2 Content features \n",
    "content_features_for_profiles = ['mata_kuliah_encoded', 'platform_encoded', 'format_encoded', 'kesulitan_encoded', 'durasi', 'rating_pengguna']\n",
    "content_features_for_training = ['mata_kuliah_encoded', 'platform_encoded', 'format_encoded', 'kesulitan_encoded', 'durasi_y', 'rating_pengguna']\n",
    "\n",
    "# 4.3 Interaction features\n",
    "interaction_features = ['feedback_score', 'completion_score', 'watch_ratio', 'durasi_tonton']\n",
    "\n",
    "# 4.4 Create user-item matrix untuk collaborative filtering\n",
    "print(\"üìä Creating user-item matrix...\")\n",
    "user_item_matrix = full_data.pivot_table(\n",
    "    index='id_mahasiswa', \n",
    "    columns='id_konten', \n",
    "    values='feedback_score', \n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ User-item matrix shape: {user_item_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3548cfb2",
   "metadata": {},
   "source": [
    "## 5. MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "63cdaf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Building Recommendation Models...\n",
      "üéØ Building Content-Based Model...\n",
      "‚úÖ Content-based features prepared\n",
      "üë• Building Collaborative Filtering Model...\n",
      "‚úÖ Similarity matrices computed\n",
      "üå≥ Building Hybrid Model with Random Forest...\n",
      "üßæ Training Data Columns: ['id_interaksi', 'id_mahasiswa', 'id_konten', 'waktu_akses', 'durasi_tonton', 'feedback', 'device', 'status', 'feedback_score', 'completion_score', 'durasi_x', 'watch_ratio', 'nama', 'jurusan', 'angkatan', 'ipk_terakhir', 'device_preference', 'learning_style', 'goal', 'waktu_belajar_per_hari', 'ketersediaan_belajar', 'judul', 'mata_kuliah', 'platform', 'format', 'durasi_y', 'kesulitan', 'rating_pengguna', 'jurusan_encoded', 'device_preference_encoded', 'learning_style_encoded', 'goal_encoded', 'ketersediaan_belajar_encoded', 'mata_kuliah_encoded', 'platform_encoded', 'format_encoded', 'kesulitan_encoded']\n",
      "‚úÖ Random Forest MSE: 1.6337\n",
      "‚úÖ Random Forest MAE: 1.1241\n",
      "\n",
      "üìä Top 5 Feature Importance:\n",
      "            feature  importance\n",
      "5      ipk_terakhir    0.180534\n",
      "12  rating_pengguna    0.140409\n",
      "13      watch_ratio    0.138158\n",
      "11         durasi_y    0.129849\n",
      "0   jurusan_encoded    0.058849\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nü§ñ Building Recommendation Models...\")\n",
    "\n",
    "# 5.1 Content-Based Filtering\n",
    "print(\"üéØ Building Content-Based Model...\")\n",
    "\n",
    "# Siapkan user profiles dan content profiles\n",
    "user_profiles = full_data.groupby('id_mahasiswa')[user_features].first()\n",
    "content_profiles = data_konten.copy()\n",
    "\n",
    "# Encode content profiles\n",
    "for feature in ['mata_kuliah', 'platform', 'format', 'kesulitan']:\n",
    "    if feature in label_encoders:\n",
    "        content_profiles[f'{feature}_encoded'] = label_encoders[feature].transform(content_profiles[feature].astype(str))\n",
    "\n",
    "# Normalisasi features\n",
    "scaler_user = StandardScaler()\n",
    "scaler_content = StandardScaler()\n",
    "\n",
    "user_profiles_scaled = scaler_user.fit_transform(user_profiles[user_features])\n",
    "content_profiles_scaled = scaler_content.fit_transform(content_profiles[content_features_for_profiles])\n",
    "\n",
    "print(\"‚úÖ Content-based features prepared\")\n",
    "\n",
    "# 5.2 Collaborative Filtering dengan Cosine Similarity\n",
    "print(\"üë• Building Collaborative Filtering Model...\")\n",
    "\n",
    "# User-based collaborative filtering\n",
    "user_similarity = cosine_similarity(user_item_matrix.values)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, \n",
    "                                 index=user_item_matrix.index, \n",
    "                                 columns=user_item_matrix.index)\n",
    "\n",
    "# Item-based collaborative filtering  \n",
    "item_similarity = cosine_similarity(user_item_matrix.T.values)\n",
    "item_similarity_df = pd.DataFrame(item_similarity,\n",
    "                                 index=user_item_matrix.columns,\n",
    "                                 columns=user_item_matrix.columns)\n",
    "\n",
    "print(\"‚úÖ Similarity matrices computed\")\n",
    "\n",
    "# 5.3 Hybrid Model dengan Random Forest\n",
    "print(\"üå≥ Building Hybrid Model with Random Forest...\")\n",
    "\n",
    "# Prepare training data\n",
    "training_data = full_data.copy()\n",
    "print(\"üßæ Training Data Columns:\", training_data.columns.tolist())\n",
    "\n",
    "\n",
    "# Features untuk hybrid model\n",
    "hybrid_features = user_features + content_features_for_training + ['watch_ratio']\n",
    "X = training_data[hybrid_features]\n",
    "y = training_data['feedback_score']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Random Forest MSE: {mse:.4f}\")\n",
    "print(f\"‚úÖ Random Forest MAE: {mae:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': hybrid_features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Top 5 Feature Importance:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a0419",
   "metadata": {},
   "source": [
    "## 5. MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9a6347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Building Recommendation Models...\n",
      "üéØ Building Content-Based Model...\n",
      "‚úÖ Content-based features prepared\n",
      "üë• Building Collaborative Filtering Model...\n",
      "‚úÖ Similarity matrices computed\n",
      "üå≥ Building Hybrid Model with Random Forest...\n",
      "‚úÖ Random Forest MSE: 1.6337\n",
      "‚úÖ Random Forest MAE: 1.1241\n",
      "\n",
      "üìä Top 5 Feature Importance:\n",
      "            feature  importance\n",
      "5      ipk_terakhir    0.180534\n",
      "12  rating_pengguna    0.140409\n",
      "13      watch_ratio    0.138158\n",
      "11         durasi_y    0.129849\n",
      "0   jurusan_encoded    0.058849\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nü§ñ Building Recommendation Models...\")\n",
    "\n",
    "# 5.1 Content-Based Filtering\n",
    "print(\"üéØ Building Content-Based Model...\")\n",
    "\n",
    "# Siapkan user profiles dan content profiles\n",
    "user_profiles = full_data.groupby('id_mahasiswa')[user_features].first()\n",
    "content_profiles = data_konten.copy()\n",
    "\n",
    "# Encode content profiles\n",
    "for feature in ['mata_kuliah', 'platform', 'format', 'kesulitan']:\n",
    "    if feature in label_encoders:\n",
    "        content_profiles[f'{feature}_encoded'] = label_encoders[feature].transform(content_profiles[feature].astype(str))\n",
    "\n",
    "# Normalisasi features\n",
    "scaler_user = StandardScaler()\n",
    "scaler_content = StandardScaler()\n",
    "\n",
    "user_profiles_scaled = scaler_user.fit_transform(user_profiles[user_features])\n",
    "content_profiles_scaled = scaler_content.fit_transform(content_profiles[content_features_for_profiles])\n",
    "\n",
    "print(\"‚úÖ Content-based features prepared\")\n",
    "\n",
    "# 5.2 Collaborative Filtering dengan Cosine Similarity\n",
    "print(\"üë• Building Collaborative Filtering Model...\")\n",
    "\n",
    "# User-based collaborative filtering\n",
    "user_similarity = cosine_similarity(user_item_matrix.values)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, \n",
    "                                 index=user_item_matrix.index, \n",
    "                                 columns=user_item_matrix.index)\n",
    "\n",
    "# Item-based collaborative filtering  \n",
    "item_similarity = cosine_similarity(user_item_matrix.T.values)\n",
    "item_similarity_df = pd.DataFrame(item_similarity,\n",
    "                                 index=user_item_matrix.columns,\n",
    "                                 columns=user_item_matrix.columns)\n",
    "\n",
    "print(\"‚úÖ Similarity matrices computed\")\n",
    "\n",
    "# 5.3 Hybrid Model dengan Random Forest\n",
    "print(\"üå≥ Building Hybrid Model with Random Forest...\")\n",
    "\n",
    "# Prepare training data\n",
    "training_data = full_data.copy()\n",
    "\n",
    "# Features untuk hybrid model\n",
    "hybrid_features = user_features + content_features_for_training + ['watch_ratio']\n",
    "X = training_data[hybrid_features]\n",
    "y = training_data['feedback_score']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Random Forest MSE: {mse:.4f}\")\n",
    "print(f\"‚úÖ Random Forest MAE: {mae:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': hybrid_features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Top 5 Feature Importance:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11693c0",
   "metadata": {},
   "source": [
    "## 6. MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f98da9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Model Evaluation...\n",
      "‚úÖ Evaluation completed for 10 users\n",
      "üìä Average ground truth items per user: 6.40\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìà Model Evaluation...\")\n",
    "\n",
    "def evaluate_recommendations(user_id, top_k=5):\n",
    "    \"\"\"Evaluate recommendation quality untuk user tertentu\"\"\"\n",
    "    # Ambil interaksi historis user\n",
    "    user_history = full_data[full_data['id_mahasiswa'] == user_id]\n",
    "    \n",
    "    if len(user_history) == 0:\n",
    "        return None\n",
    "        \n",
    "    # Ground truth: konten dengan rating tinggi (>= 4)\n",
    "    ground_truth = set(user_history[user_history['feedback_score'] >= 4]['id_konten'].values)\n",
    "    \n",
    "    return len(ground_truth)\n",
    "\n",
    "# Sample evaluation\n",
    "sample_users = user_item_matrix.index[:10]  \n",
    "eval_results = []\n",
    "\n",
    "for user_id in sample_users:\n",
    "    gt_count = evaluate_recommendations(user_id)\n",
    "    if gt_count is not None:\n",
    "        eval_results.append({'user_id': user_id, 'ground_truth_count': gt_count})\n",
    "\n",
    "eval_df = pd.DataFrame(eval_results)\n",
    "print(f\"‚úÖ Evaluation completed for {len(eval_df)} users\")\n",
    "print(f\"üìä Average ground truth items per user: {eval_df['ground_truth_count'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c4b81",
   "metadata": {},
   "source": [
    "## 7. SAVE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c182b84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saving models and encoders...\n",
      "‚úÖ Saved rf_model.pkl\n",
      "‚úÖ Saved user_item_matrix.pkl\n",
      "‚úÖ Saved user_similarity_df.pkl\n",
      "‚úÖ Saved item_similarity_df.pkl\n",
      "‚úÖ Saved label_encoders.pkl\n",
      "‚úÖ Saved scaler_user.pkl\n",
      "‚úÖ Saved scaler_content.pkl\n",
      "‚úÖ Saved user_profiles.pkl\n",
      "‚úÖ Saved content_profiles.pkl\n",
      "‚úÖ Saved hybrid_features.pkl\n",
      "‚úÖ Saved user_features.pkl\n",
      "‚úÖ Saved content_features.pkl\n",
      "\n",
      "üéâ Model development completed!\n",
      "üìÅ Files created:\n",
      "   - rf_model.pkl (Random Forest model)\n",
      "   - user_item_matrix.pkl (User-item interaction matrix)\n",
      "   - user_similarity_df.pkl (User similarity matrix)\n",
      "   - item_similarity_df.pkl (Item similarity matrix)\n",
      "   - label_encoders.pkl (Label encoders)\n",
      "   - scaler_user.pkl & scaler_content.pkl (Feature scalers)\n",
      "   - user_profiles.pkl & content_profiles.pkl (Profile data)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüíæ Saving models and encoders...\")\n",
    "\n",
    "models_to_save = {\n",
    "    \"rf_model\": rf_model,\n",
    "    \"user_item_matrix\": user_item_matrix,\n",
    "    \"user_similarity_df\": user_similarity_df,\n",
    "    \"item_similarity_df\": item_similarity_df,\n",
    "    \"label_encoders\": label_encoders,\n",
    "    \"scaler_user\": scaler_user,\n",
    "    \"scaler_content\": scaler_content,\n",
    "    \"user_profiles\": user_profiles,\n",
    "    \"content_profiles\": content_profiles,\n",
    "    'hybrid_features': hybrid_features,\n",
    "    'user_features': user_features,\n",
    "    'content_features': content_features_for_profiles\n",
    "}\n",
    "\n",
    "# Save models\n",
    "for name, model in models_to_save.items():\n",
    "    with open(f'{name}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"‚úÖ Saved {name}.pkl\")\n",
    "\n",
    "print(\"\\nüéâ Model development completed!\")\n",
    "print(\"üìÅ Files created:\")\n",
    "print(\"   - rf_model.pkl (Random Forest model)\")\n",
    "print(\"   - user_item_matrix.pkl (User-item interaction matrix)\")\n",
    "print(\"   - user_similarity_df.pkl (User similarity matrix)\")\n",
    "print(\"   - item_similarity_df.pkl (Item similarity matrix)\")\n",
    "print(\"   - label_encoders.pkl (Label encoders)\")\n",
    "print(\"   - scaler_user.pkl & scaler_content.pkl (Feature scalers)\")\n",
    "print(\"   - user_profiles.pkl & content_profiles.pkl (Profile data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861e365",
   "metadata": {},
   "source": [
    "## 8. QUICK TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc63c670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Quick Test...\n",
      "üéØ Top 5 recommendations for MHS001:\n",
      "   1. Behavior reality issue last mother apply... (Score: 5.000)\n",
      "   2. He candidate investment out natural... (Score: 2.000)\n",
      "   3. Employee result manager... (Score: 2.000)\n",
      "   4. Finish land never can... (Score: 2.000)\n",
      "   5. Whole local begin source cultural marriage item... (Score: 2.000)\n",
      "\n",
      "‚úÖ Notebook execution completed! Ready for production deployment.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüß™ Quick Test...\")\n",
    "\n",
    "def quick_recommend_test(user_id, top_k=5):\n",
    "    \"\"\"Test rekomendasi untuk user tertentu\"\"\"\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        print(f\"‚ùå User {user_id} tidak ditemukan\")\n",
    "        return\n",
    "        \n",
    "    # Ambil user profile\n",
    "    user_profile = user_profiles.loc[user_id]\n",
    "    \n",
    "    # Hybrid approach: gabung collaborative + content-based\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    unrated_items = user_ratings[user_ratings == 0].index\n",
    "    \n",
    "    if len(unrated_items) == 0:\n",
    "        print(f\"‚ú® User {user_id} sudah menilai semua konten\")\n",
    "        return\n",
    "        \n",
    "    # Simple collaborative filtering prediction\n",
    "    similar_users = user_similarity_df.loc[user_id].nlargest(10).index[1:]  # Exclude self\n",
    "    \n",
    "    recommendations = []\n",
    "    for item in unrated_items[:20]:  # Sample untuk test\n",
    "        # Collaborative score\n",
    "        collab_score = 0\n",
    "        count = 0\n",
    "        for sim_user in similar_users:\n",
    "            if user_item_matrix.loc[sim_user, item] > 0:\n",
    "                collab_score += user_item_matrix.loc[sim_user, item]\n",
    "                count += 1\n",
    "        \n",
    "        if count > 0:\n",
    "            collab_score /= count\n",
    "            recommendations.append((item, collab_score))\n",
    "    \n",
    "    # Sort dan ambil top-k\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_recommendations = recommendations[:top_k]\n",
    "    \n",
    "    print(f\"üéØ Top {top_k} recommendations for {user_id}:\")\n",
    "    for i, (item_id, score) in enumerate(top_recommendations, 1):\n",
    "        item_info = data_konten[data_konten['id_konten'] == item_id].iloc[0]\n",
    "        print(f\"   {i}. {item_info['judul'][:50]}... (Score: {score:.3f})\")\n",
    "\n",
    "# Test dengan user pertama\n",
    "if len(user_item_matrix.index) > 0:\n",
    "    test_user = user_item_matrix.index[0]\n",
    "    quick_recommend_test(test_user)\n",
    "\n",
    "print(\"\\n‚úÖ Notebook execution completed! Ready for production deployment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
